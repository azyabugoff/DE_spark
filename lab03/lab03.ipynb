{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%AddDeps org.elasticsearch elasticsearch-spark-20_2.11 6.8.9\n",
    "%AddDeps com.datastax.spark spark-cassandra-connector_2.11 2.4.3\n",
    "%AddDeps org.postgresql postgresql 42.2.12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Elasticsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val ES_USERNAME: String = \"***\"\n",
    "val ES_PASSWORD: String = \"***\"\n",
    "val ELASTIC_HOST = \"10.0.0.5:9200\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.elasticsearch.spark.sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val esOptions =\n",
    "    Map(\n",
    "      \"es.nodes\" -> ELASTIC_HOST,\n",
    "      \"es.batch.write.refresh\" -> \"false\",\n",
    "      \"es.net.http.auth.user\" -> ES_USERNAME,\n",
    "      \"es.net.http.auth.pass\" -> ES_PASSWORD,\n",
    "      \"es.nodes.wan.only\" -> \"true\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var shops = spark\n",
    "                .read\n",
    "                .format(\"org.elasticsearch.spark.sql\")\n",
    "                .options(esOptions)\n",
    "                .load(\"visits\")\n",
    "                .toDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HDFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.apache.spark.sql.types._\n",
    "import org.apache.spark.sql.functions._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val input = spark.read\n",
    "                .option(\"header\",true)\n",
    "                .json(\"/labs/laba03/weblogs.json\").toDF\n",
    "                .select('uid, explode(col(\"visits\")))\n",
    "                .select('uid, col(\"col.*\"))\n",
    "                .toDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val webLogs = input.na.drop(List(\"uid\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cassandra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val CASSANDRA_HOST = \"10.0.0.5\"\n",
    "val CASSANDRA_PORT = \"9042\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.conf.set(\"spark.cassandra.connection.host\", CASSANDRA_HOST)\n",
    "spark.conf.set(\"spark.cassandra.connection.port\", CASSANDRA_PORT)\n",
    "spark.conf.set(\"spark.cassandra.output.consistency.level\", \"ANY\")\n",
    "spark.conf.set(\"spark.cassandra.input.consistency.level\", \"ONE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val cOpts = Map(\"table\" -> \"clients\", \"keyspace\" -> \"labdata\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val clients = spark\n",
    "                .read\n",
    "                .format(\"org.apache.spark.sql.cassandra\")\n",
    "                .options(cOpts)\n",
    "                .load\n",
    "                .toDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PostgreSQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val POSTGRE_USER = \"***\"\n",
    "val POSTGRE_URL = s\"jdbc:postgresql://10.0.0.5:5432/labdata?user=$POSTGRE_USER&password=$ES_PASSWORD\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.postgresql.Driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val pgOptions = Map(\n",
    "        \"url\" -> POSTGRE_URL,\n",
    "        \"dbtable\" -> \"domain_cats\",\n",
    "        \"user\" -> POSTGRE_USER,\n",
    "        \"password\" -> ES_PASSWORD,\n",
    "        \"driver\" -> \"org.postgresql.Driver\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val webCats = spark\n",
    "    .read\n",
    "    .format(\"jdbc\")\n",
    "    .options(pgOptions)\n",
    "    .load\n",
    "    .toDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main part"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Используя **psql**, создайте в вашей базе данных name_surname таблицу clients со следующими колонками:\n",
    "\n",
    "*uid, gender, age_cat, shop_cat1, ... , shop_catN, web_cat1, ... , web_catN*\n",
    "\n",
    "где:\n",
    "\n",
    "* **uid** (primary key) – uid пользователя.\n",
    "* **gender** – пол пользователя: M, F.\n",
    "* **age_cat** – категория возраста, одна из пяти: 18-24, 25-34, 35-44, 45-54, >=55.\n",
    "* **shop_cat**, **web_cat** – категории товаров и категории веб-сайтов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  0. Clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val new_col = when(clients(\"age\").between(18, 24), \"18-24\")\n",
    "                .when(clients(\"age\").between(25, 34), \"25-34\")\n",
    "                .when(clients(\"age\").between(35, 44), \"35-44\")\n",
    "                .when(clients(\"age\").between(45, 54), \"45-54\")\n",
    "                .when(clients(\"age\") >= 55, \">=55\")\n",
    "val cat_clients_age = clients.withColumn(\"age_cat\", new_col)\n",
    "val cat_clients = cat_clients_age.drop(\"age\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Websites & categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.apache.spark.sql.functions.udf\n",
    "import scala.util.Try\n",
    "import java.net.URL\n",
    "import java.net.URLDecoder.decode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val decode_url = udf { (url: String) => Try(new URL(decode(url, \"UTF-8\")).getHost).toOption}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val filtered_logs = webLogs\n",
    "            .filter('url.startsWith(\"http\"))\n",
    "            .withColumn(\"url\", decode_url(col(\"url\")))\n",
    "            .withColumn(\"url\", regexp_replace('url, \"^www.\", \"\"))\n",
    "            .dropDuplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val websitesWithCats = filtered_logs\n",
    "                .join(webCats, filtered_logs(\"url\") === webCats(\"domain\"))\n",
    "                .groupBy(\"uid\", \"category\").count\n",
    "                .withColumn(\"category\", concat(lit(\"web_\"), col(\"category\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val usersToCats = websitesWithCats\n",
    "    .groupBy(\"uid\")\n",
    "    .pivot(\"category\")\n",
    "    .sum(\"count\")\n",
    "    .na.fill(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Shops & categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val shopsWithCats = shops\n",
    "            .select('uid, 'category)\n",
    "            .withColumn(\"category\", lower(col(\"category\")))\n",
    "            .withColumn(\"category\", regexp_replace('category, \"[ -]\", \"_\"))\n",
    "            .groupBy(\"uid\", \"category\").count\n",
    "            .withColumn(\"category\", concat(lit(\"shop_\"), col(\"category\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val usersToShops = shopsWithCats\n",
    "    .groupBy(\"uid\")\n",
    "    .pivot(\"category\")\n",
    "    .sum(\"count\")\n",
    "    .na.fill(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Join Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val right = usersToShops.withColumnRenamed(\"uid\", \"right_uid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val tmp = cat_clients\n",
    "            .join(right, right(\"right_uid\") === cat_clients(\"uid\"), \"left\")\n",
    "            .drop(\"right_uid\")\n",
    "            .na.fill(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val right1 = usersToCats.withColumnRenamed(\"uid\", \"right_uid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val res = tmp\n",
    "            .join(right1, right1(\"right_uid\") === tmp(\"uid\"), \"left\")\n",
    "            .drop(\"right_uid\")\n",
    "            .na.fill(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving result in PostgreSQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val writeOptions = Map(\n",
    "        \"url\" -> \"jdbc:postgresql://10.0.0.5:5432/***\",\n",
    "        \"dbtable\" -> \"clients\",\n",
    "        \"user\" -> POSTGRE_USER,\n",
    "        \"password\" -> ES_PASSWORD,\n",
    "        \"driver\" -> \"org.postgresql.Driver\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res\n",
    "    .write\n",
    "    .format(\"jdbc\")\n",
    "    .options(writeOptions)\n",
    "    .mode(\"overwrite\")\n",
    "    .save"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Apache Toree - Scala",
   "language": "scala",
   "name": "apache_toree_scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "2.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
