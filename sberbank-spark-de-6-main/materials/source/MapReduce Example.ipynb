{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We're no strangers to love\r\n",
      "You know the rules and so do I\r\n",
      "A full commitment's what I'm thinking of\r\n",
      "You wouldn't get this from any other guy\r\n",
      "I just wanna tell you how I'm feeling\r\n",
      "Gotta make you understand\r\n",
      "Never gonna give you up\r\n",
      "Never gonna let you down\r\n",
      "Never gonna run around and desert you\r\n",
      "Never gonna make you cry\r\n",
      "Never gonna say goodbye\r\n",
      "Never gonna tell a lie and hurt you\r\n",
      "We've known each other for so long\r\n",
      "Your heart's been aching but you're too shy to say it\r\n",
      "Inside we both know what's been going on\r\n",
      "We know the game and we're gonna play it\r\n",
      "And if you ask me how I'm feeling\r\n",
      "Don't tell me you're too blind to see\r\n",
      "Never gonna give you up\r\n",
      "Never gonna let you down\r\n",
      "Never gonna run around and desert you\r\n",
      "Never gonna make you cry\r\n",
      "Never gonna say goodbye\r\n",
      "Never gonna tell a lie and hurt you\r\n",
      "Never gonna give you up\r\n",
      "Never gonna let you down\r\n",
      "Never gonna run around and desert you\r\n",
      "Never gonna make you cry\r\n",
      "Never gonna say goodbye\r\n",
      "Never gonna tell a lie and hurt you\r\n",
      "Never gonna give, never gonna give\r\n",
      "(Give you up)\r\n",
      "(Ooh) Never gonna give, never gonna give\r\n",
      "(Give you up)\r\n",
      "We've known each other for so long\r\n",
      "Your heart's been aching but you're too shy to say it\r\n",
      "Inside we both know what's been going on\r\n",
      "We know the game and we're gonna play it\r\n",
      "I just wanna tell you how I'm feeling\r\n",
      "Gotta make you understand\r\n",
      "Never gonna give you up\r\n",
      "Never gonna let you down\r\n",
      "Never gonna run around and desert you\r\n",
      "Never gonna make you cry\r\n",
      "Never gonna say goodbye\r\n",
      "Never gonna tell a lie and hurt you\r\n",
      "Never gonna give you up\r\n",
      "Never gonna let you down\r\n",
      "Never gonna run around and desert you\r\n",
      "Never gonna make you cry\r\n",
      "Never gonna say goodbye\r\n",
      "Never gonna tell a lie and hurt you\r\n",
      "Never gonna give you up\r\n",
      "Never gonna let you down\r\n",
      "Never gonna run around and desert you\r\n",
      "Never gonna make you cry\r\n"
     ]
    }
   ],
   "source": [
    "! cat never_lyrics.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "! hdfs dfs -mkdir -p /tmp/mapred-example/input/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "! hdfs dfs -put never_lyrics.txt /tmp/mapred-example/input/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/04/20 22:23:40 INFO client.RMProxy: Connecting to ResourceManager at spark-ds-master1.newprolab.com/10.0.0.11:8050\n",
      "20/04/20 22:23:41 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /user/egor.mateshuk/.staging/job_1587370361045_0011\n",
      "20/04/20 22:23:42 INFO input.FileInputFormat: Total input files to process : 1\n",
      "20/04/20 22:23:47 INFO mapreduce.JobSubmitter: number of splits:1\n",
      "20/04/20 22:23:48 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1587370361045_0011\n",
      "20/04/20 22:23:48 INFO mapreduce.JobSubmitter: Executing with tokens: []\n",
      "20/04/20 22:23:49 INFO conf.Configuration: found resource resource-types.xml at file:/etc/hadoop/3.1.4.0-315/0/resource-types.xml\n",
      "20/04/20 22:23:49 INFO impl.YarnClientImpl: Submitted application application_1587370361045_0011\n",
      "20/04/20 22:23:49 INFO mapreduce.Job: The url to track the job: http://spark-ds-master1.newprolab.com:8088/proxy/application_1587370361045_0011/\n",
      "20/04/20 22:23:49 INFO mapreduce.Job: Running job: job_1587370361045_0011\n",
      "20/04/20 22:24:07 INFO mapreduce.Job: Job job_1587370361045_0011 running in uber mode : false\n",
      "20/04/20 22:24:07 INFO mapreduce.Job:  map 0% reduce 0%\n",
      "20/04/20 22:24:12 INFO mapreduce.Job:  map 100% reduce 0%\n",
      "20/04/20 22:24:18 INFO mapreduce.Job:  map 100% reduce 100%\n",
      "20/04/20 22:24:21 INFO mapreduce.Job: Job job_1587370361045_0011 completed successfully\n",
      "20/04/20 22:24:21 INFO mapreduce.Job: Counters: 53\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=973\n",
      "\t\tFILE: Number of bytes written=470327\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=1907\n",
      "\t\tHDFS: Number of bytes written=623\n",
      "\t\tHDFS: Number of read operations=8\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of write operations=2\n",
      "\tJob Counters \n",
      "\t\tLaunched map tasks=1\n",
      "\t\tLaunched reduce tasks=1\n",
      "\t\tData-local map tasks=1\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=9798\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=8886\n",
      "\t\tTotal time spent by all map tasks (ms)=3266\n",
      "\t\tTotal time spent by all reduce tasks (ms)=2962\n",
      "\t\tTotal vcore-milliseconds taken by all map tasks=3266\n",
      "\t\tTotal vcore-milliseconds taken by all reduce tasks=2962\n",
      "\t\tTotal megabyte-milliseconds taken by all map tasks=45149184\n",
      "\t\tTotal megabyte-milliseconds taken by all reduce tasks=40946688\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=56\n",
      "\t\tMap output records=349\n",
      "\t\tMap output bytes=3154\n",
      "\t\tMap output materialized bytes=973\n",
      "\t\tInput split bytes=149\n",
      "\t\tCombine input records=349\n",
      "\t\tCombine output records=87\n",
      "\t\tReduce input groups=87\n",
      "\t\tReduce shuffle bytes=973\n",
      "\t\tReduce input records=87\n",
      "\t\tReduce output records=87\n",
      "\t\tSpilled Records=174\n",
      "\t\tShuffled Maps =1\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=1\n",
      "\t\tGC time elapsed (ms)=122\n",
      "\t\tCPU time spent (ms)=2620\n",
      "\t\tPhysical memory (bytes) snapshot=2715791360\n",
      "\t\tVirtual memory (bytes) snapshot=21351247872\n",
      "\t\tTotal committed heap usage (bytes)=2945974272\n",
      "\t\tPeak Map Physical memory (bytes)=2416496640\n",
      "\t\tPeak Map Virtual memory (bytes)=10659667968\n",
      "\t\tPeak Reduce Physical memory (bytes)=299294720\n",
      "\t\tPeak Reduce Virtual memory (bytes)=10691579904\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=1758\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=623\n"
     ]
    }
   ],
   "source": [
    "! hadoop jar /usr/hdp/current/hadoop-mapreduce-client/hadoop-mapreduce-examples-3.1.1.3.1.4.0-315.jar wordcount /tmp/mapred-example/input /tmp/mapred-example/output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 items\r\n",
      "-rw-r--r--   3 egor.mateshuk hdfs          0 2020-04-20 22:24 /tmp/mapred-example/output/_SUCCESS\r\n",
      "-rw-r--r--   3 egor.mateshuk hdfs        623 2020-04-20 22:24 /tmp/mapred-example/output/part-r-00000\r\n"
     ]
    }
   ],
   "source": [
    "! hdfs dfs -ls /tmp/mapred-example/output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Give\t2\r\n",
      "(Ooh)\t1\r\n",
      "A\t1\r\n",
      "And\t1\r\n",
      "Don't\t1\r\n",
      "Gotta\t2\r\n",
      "I\t3\r\n",
      "I'm\t4\r\n",
      "Inside\t2\r\n",
      "Never\t36\r\n",
      "We\t2\r\n",
      "We're\t1\r\n",
      "We've\t2\r\n",
      "You\t2\r\n",
      "Your\t2\r\n",
      "a\t5\r\n",
      "aching\t2\r\n",
      "and\t14\r\n",
      "any\t1\r\n",
      "around\t6\r\n",
      "ask\t1\r\n",
      "been\t4\r\n",
      "blind\t1\r\n",
      "both\t2\r\n",
      "but\t2\r\n",
      "commitment's\t1\r\n",
      "cry\t6\r\n",
      "desert\t6\r\n",
      "do\t1\r\n",
      "down\t6\r\n",
      "each\t2\r\n",
      "feeling\t3\r\n",
      "for\t2\r\n",
      "from\t1\r\n",
      "full\t1\r\n",
      "game\t2\r\n",
      "get\t1\r\n",
      "give\t8\r\n",
      "give,\t2\r\n",
      "going\t2\r\n",
      "gonna\t40\r\n",
      "goodbye\t5\r\n",
      "guy\t1\r\n",
      "heart's\t2\r\n",
      "how\t3\r\n",
      "hurt\t5\r\n",
      "if\t1\r\n",
      "it\t4\r\n",
      "just\t2\r\n",
      "know\t5\r\n",
      "known\t2\r\n",
      "let\t6\r\n",
      "lie\t5\r\n",
      "long\t2\r\n",
      "love\t1\r\n",
      "make\t8\r\n",
      "me\t2\r\n",
      "never\t2\r\n",
      "no\t1\r\n",
      "of\t1\r\n",
      "on\t2\r\n",
      "other\t3\r\n",
      "play\t2\r\n",
      "rules\t1\r\n",
      "run\t6\r\n",
      "say\t7\r\n",
      "see\t1\r\n",
      "shy\t2\r\n",
      "so\t3\r\n",
      "strangers\t1\r\n",
      "tell\t8\r\n",
      "the\t3\r\n",
      "thinking\t1\r\n",
      "this\t1\r\n",
      "to\t4\r\n",
      "too\t3\r\n",
      "understand\t2\r\n",
      "up\t6\r\n",
      "up)\t2\r\n",
      "wanna\t2\r\n",
      "we\t2\r\n",
      "we're\t2\r\n",
      "what\t1\r\n",
      "what's\t2\r\n",
      "wouldn't\t1\r\n",
      "you\t36\r\n",
      "you're\t3\r\n"
     ]
    }
   ],
   "source": [
    "! hdfs dfs -cat /tmp/mapred-example/output/part-r-00000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/04/20 22:25:28 INFO fs.TrashPolicyDefault: Moved: 'hdfs://spark-ds-master1.newprolab.com:8020/tmp/mapred-example' to trash at: hdfs://spark-ds-master1.newprolab.com:8020/user/egor.mateshuk/.Trash/Current/tmp/mapred-example\r\n"
     ]
    }
   ],
   "source": [
    "! hdfs dfs -rm -r /tmp/mapred-example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SLF4J: Class path contains multiple SLF4J bindings.\n",
      "SLF4J: Found binding in [jar:file:/usr/hdp/3.1.4.0-315/hive/lib/log4j-slf4j-impl-2.10.0.jar!/org/slf4j/impl/StaticLoggerBinder.class]\n",
      "SLF4J: Found binding in [jar:file:/usr/hdp/3.1.4.0-315/hadoop/lib/slf4j-log4j12-1.7.25.jar!/org/slf4j/impl/StaticLoggerBinder.class]\n",
      "SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.\n",
      "SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]\n",
      "Connecting to jdbc:hive2://spark-ds-node1.newprolab.com:2181,spark-ds-master1.newprolab.com:2181,spark-ds-master2.newprolab.com:2181/default;password=egor.mateshuk;serviceDiscoveryMode=zooKeeper;user=egor.mateshuk;zooKeeperNamespace=hiveserver2\n",
      "20/04/20 22:22:41 [main]: INFO jdbc.HiveConnection: Connected to spark-ds-node1.newprolab.com:10000\n",
      "Connected to: Apache Hive (version 3.1.0.3.1.4.0-315)\n",
      "Driver: Hive JDBC (version 3.1.0.3.1.4.0-315)\n",
      "Transaction isolation: TRANSACTION_REPEATABLE_READ\n",
      "Error: Error while compiling statement: FAILED: SemanticException [Error 10001]: Line 1:14 Table not found 'asdf' (state=42S02,code=10001)\n",
      "Closing: 0: jdbc:hive2://spark-ds-node1.newprolab.com:2181,spark-ds-master1.newprolab.com:2181,spark-ds-master2.newprolab.com:2181/default;password=egor.mateshuk;serviceDiscoveryMode=zooKeeper;user=egor.mateshuk;zooKeeperNamespace=hiveserver2\n"
     ]
    }
   ],
   "source": [
    "! hive -e \"select * from asdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
